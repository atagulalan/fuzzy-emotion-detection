<!DOCTYPE html>
<html>
<head>
  <script src="js/face-api.js"></script>
  <script src="js/functions.js"></script>
  <script src="js/main.js"></script>
  <link rel="stylesheet" href="css/styles.css">
</head>
<body>
  <video onloadedmetadata="onPlay(this)" id="inputVideo" autoplay muted playsinline></video>
  <div id="center">
    <canvas id="overlay" width="480" height="480" />
  </div>
</body>

  <script>
    const videoEl = document.getElementById('inputVideo')
    const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 256, scoreThreshold: 0 })
    const canvas = document.getElementById('overlay')
    const ctx = canvas.getContext('2d')

    async function onPlay() {
      if(videoEl.paused || videoEl.ended || !(!!faceapi.nets.tinyFaceDetector.params))
        return setTimeout(() => onPlay())

      const result = await faceapi.detectSingleFace(videoEl, options).withFaceLandmarks()
      draw(result, videoEl, canvas, ctx) 
      setTimeout(() => onPlay())
    }

    async function run() {
      // load face detection and face landmark models
      await faceapi.loadFaceLandmarkModel('./weights/')

      // try to access users webcam and stream the images
      // to the video element
      const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
      const videoEl = document.getElementById('inputVideo')
      videoEl.srcObject = stream
    }



    function ready(fn) {
      if (document.readyState != 'loading'){
        fn()
      } else {
        document.addEventListener('DOMContentLoaded', fn);
      }
    }

    ready(()=>{
      faceapi.nets.tinyFaceDetector.load('./weights/')
      run()
    })
  </script>
</body>
</html>
